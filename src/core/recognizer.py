import os
import sys
import json
import queue
import requests
import zipfile
import sounddevice as sd
import io
import tempfile
from pathlib import Path
from tqdm import tqdm
from vosk import Model, KaldiRecognizer, SetLogLevel
import speech_recognition as sr
from scipy.io.wavfile import write as wav_write


class Recognizer:
    """
    ÐŸÐ¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Recognizer:
    - ÐžÐ½Ð»Ð°Ð¹Ð½ (Google Speech)
    - ÐžÑ„Ñ„Ð»Ð°Ð¹Ð½ (Vosk)
    - ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½ Ð½Ðµ Ð²Ñ‹ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ÑÑ Ð¼ÐµÐ¶Ð´Ñƒ Ñ„Ñ€Ð°Ð·Ð°Ð¼Ð¸
    """

    def __init__(self, config):
        self.config = config
        self.default_lang = config.get("assistant", {}).get("default_language", "ru")
        self.language_map = {"ru": "ru-RU", "en": "en-US", "uz": "uz-UZ"}

        self.models_dir = Path("data/models")
        self.models_dir.mkdir(parents=True, exist_ok=True)

        self.vosk_models = {
            "ru": self.models_dir / "vosk-model-small-ru-0.22",
            "en": self.models_dir / "vosk-model-small-en-us-0.15",
            "uz": self.models_dir / "vosk-model-small-uz-0.22",
        }

        self.vosk_urls = {
            "ru": "https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip",
            "en": "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip",
            "uz": "https://alphacephei.com/vosk/models/vosk-model-small-uz-0.22.zip",
        }

        SetLogLevel(-1)
        self.online_available = self._check_internet()
        self._ensure_vosk_models()
        self.vosk_recognizers = self._load_vosk_recognizers()

        self.mode = "online" if self.online_available else "offline"
        print(f"ðŸŒ Ð ÐµÐ¶Ð¸Ð¼: {self.mode.upper()}")
        print(f"ðŸ—£ï¸ Ð¢ÐµÐºÑƒÑ‰Ð¸Ð¹ ÑÐ·Ñ‹Ðº: {self.default_lang.upper()}")

        # ÐžÑ‡ÐµÑ€ÐµÐ´ÑŒ Ð°ÑƒÐ´Ð¸Ð¾ Ð¸ Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾Ñ‚Ð¾Ðº
        self.audio_queue = queue.Queue()
        self.stream = None
        self._start_microphone_stream()

    # === Ð˜Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ ===
    def _check_internet(self):
        try:
            requests.get("https://www.google.com", timeout=3)
            return True
        except requests.RequestException:
            return False

    # === ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ===
    def _ensure_vosk_models(self):
        for lang, path in self.vosk_models.items():
            if not path.exists() and self.online_available:
                print(f"ðŸ“¦ Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ {lang.upper()}...")
                self._download_model(self.vosk_urls[lang])

    def _download_model(self, url):
        tmp_file = Path(tempfile.gettempdir()) / "vosk_model.zip"
        with requests.get(url, stream=True, timeout=30) as r:
            r.raise_for_status()
            total = int(r.headers.get("Content-Length", 0))
            with open(tmp_file, "wb") as f, tqdm(total=total, unit="B", unit_scale=True) as bar:
                for chunk in r.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        bar.update(len(chunk))

        with zipfile.ZipFile(tmp_file, "r") as zf:
            zf.extractall(self.models_dir)
        os.remove(tmp_file)
        print("âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°!")

    # === Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Vosk ===
    def _load_vosk_recognizers(self):
        recs = {}
        for lang, path in self.vosk_models.items():
            if path.exists():
                model = Model(str(path))
                recs[lang] = KaldiRecognizer(model, 16000)
        return recs

    # === ÐŸÐ¾ÑÑ‚Ð¾ÑÐ½Ð½Ñ‹Ð¹ Ð°ÑƒÐ´Ð¸Ð¾Ð¿Ð¾Ñ‚Ð¾Ðº ===
    def _start_microphone_stream(self):
        def callback(indata, frames, time_, status):
            if status:
                print(f"[AUDIO WARNING] {status}")
            self.audio_queue.put(bytes(indata))

        print("ðŸŽ¤ ÐœÐ¸ÐºÑ€Ð¾Ñ„Ð¾Ð½ Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½ (Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼)")
        self.stream = sd.RawInputStream(
            samplerate=16000,
            blocksize=8000,
            dtype="int16",
            channels=1,
            callback=callback
        )
        self.stream.start()

    # === Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ ===
    def listen_text(self):
        """
        Ð¡Ð»ÑƒÑˆÐ°ÐµÑ‚ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½ Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ñ‚ÐµÐºÑÑ‚, ÐºÐ¾Ð³Ð´Ð° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð° Ñ„Ñ€Ð°Ð·Ð°.
        """
        if self.mode == "online":
            return self._listen_online()
        else:
            return self._listen_offline()

    # === ÐžÐ½Ð»Ð°Ð¹Ð½ (Google) ===
    def _listen_online(self):
        print("ðŸŽ™ï¸ (Online) Ð“Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚Ðµ...")

        samplerate = 16000
        duration = 5

        try:
            with sd.InputStream(samplerate=samplerate, channels=1, dtype="int16") as stream:
                audio_data = stream.read(int(samplerate * duration))[0]
        except Exception as e:
            print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°ÑƒÐ´Ð¸Ð¾-Ð¿Ð¾Ñ‚Ð¾ÐºÐ°: {e}")
            return "", self.default_lang

        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ñ Ð² wav Ð¸ Google Speech
        wav_bytes = io.BytesIO()
        wav_write(wav_bytes, samplerate, audio_data)
        wav_bytes.seek(0)

        r = sr.Recognizer()
        with sr.AudioFile(wav_bytes) as source:
            audio = r.record(source)

        lang_code = self.language_map.get(self.default_lang, "ru-RU")
        try:
            text = r.recognize_google(audio, language=lang_code)
            print(f"ðŸ§  Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¾ ({self.default_lang.upper()}): {text}")
            return text, self.default_lang
        except sr.UnknownValueError:
            print("ðŸ¤” ÐÐµ Ð¿Ð¾Ð½ÑÐ», Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚Ðµ...")
            return "", self.default_lang
        except sr.RequestError:
            print("âš ï¸ Ð˜Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚ Ð¿Ñ€Ð¾Ð¿Ð°Ð» â€” Ð¾Ñ„Ð»Ð°Ð¹Ð½ Ñ€ÐµÐ¶Ð¸Ð¼.")
            self.mode = "offline"
            return self._listen_offline()

    # === ÐžÑ„Ð»Ð°Ð¹Ð½ (Vosk) ===
    def _listen_offline(self):
        lang = self.default_lang
        recognizer = self.vosk_recognizers.get(lang)
        if not recognizer:
            print(f"âš ï¸ ÐÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ {lang.upper()}")
            return "", lang

        while True:
            data = self.audio_queue.get()
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                text = result.get("text", "").strip()
                if text:
                    print(f"ðŸ—£ï¸ {text}")
                    return text, lang

    # === Ð¡Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… ===
    def _collect_audio(self, seconds=5):
        """Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ Ð±Ð»Ð¾ÐºÐ¸ Ð·Ð° ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ."""
        frames = []
        start = sd.get_stream().time if self.stream else 0
        duration = seconds
        while True:
            try:
                frames.append(self.audio_queue.get(timeout=seconds))
                if len(frames) * 0.5 > duration:  # Ð¿Ñ€Ð¸Ð±Ð»Ð¸Ð·Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ seconds
                    break
            except queue.Empty:
                break
        if not frames:
            return None
        import numpy as np
        return np.frombuffer(b"".join(frames), dtype="int16")
