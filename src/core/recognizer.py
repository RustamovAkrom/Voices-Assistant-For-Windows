import os
import sys
import json
import queue
import requests
import zipfile
import sounddevice as sd
import io
import tempfile
from pathlib import Path
from tqdm import tqdm
from vosk import Model, KaldiRecognizer, SetLogLevel
import speech_recognition as sr
from scipy.io.wavfile import write as wav_write


class Recognizer:
    """
    –ü–æ—Å—Ç–æ—è–Ω–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã–π Recognizer:
    - –û–Ω–ª–∞–π–Ω (Google Speech)
    - –û—Ñ—Ñ–ª–∞–π–Ω (Vosk)
    - –ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –≤—ã–∫–ª—é—á–∞–µ—Ç—Å—è –º–µ–∂–¥—É —Ñ—Ä–∞–∑–∞–º–∏
    """

    def __init__(self, config):
        self.config = config
        self.default_lang = config.get("assistant", {}).get("default_language", "ru")
        self.language_map = {"ru": "ru-RU", "en": "en-US", "uz": "uz-UZ"}

        self.models_dir = Path("data/models")
        self.models_dir.mkdir(parents=True, exist_ok=True)

        self.vosk_models = {
            "ru": self.models_dir / "vosk-model-small-ru-0.22",
            "en": self.models_dir / "vosk-model-small-en-us-0.15",
            "uz": self.models_dir / "vosk-model-small-uz-0.22",
        }

        self.vosk_urls = {
            "ru": "https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip",
            "en": "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip",
            "uz": "https://alphacephei.com/vosk/models/vosk-model-small-uz-0.22.zip",
        }

        SetLogLevel(-1)
        self.online_available = self._check_internet()
        self._ensure_vosk_models()
        self.vosk_recognizers = self._load_vosk_recognizers()

        self.mode = "online" if self.online_available else "offline"
        print(f"üåê –†–µ–∂–∏–º: {self.mode.upper()}")
        print(f"üó£Ô∏è –¢–µ–∫—É—â–∏–π —è–∑—ã–∫: {self.default_lang.upper()}")

        # –û—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ –∏ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø–æ—Ç–æ–∫
        self.audio_queue = queue.Queue()
        self.stream = None
        self._start_microphone_stream()

    # === –ò–Ω—Ç–µ—Ä–Ω–µ—Ç ===
    def _check_internet(self):
        try:
            requests.get("https://www.google.com", timeout=3)
            return True
        except requests.RequestException:
            return False

    # === –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏ ===
    def _ensure_vosk_models(self):
        for lang, path in self.vosk_models.items():
            if not path.exists() and self.online_available:
                print(f"üì¶ –°–∫–∞—á–∏–≤–∞—é –º–æ–¥–µ–ª—å –¥–ª—è {lang.upper()}...")
                self._download_model(self.vosk_urls[lang])

    def _download_model(self, url):
        tmp_file = Path(tempfile.gettempdir()) / "vosk_model.zip"
        with requests.get(url, stream=True, timeout=30) as r:
            r.raise_for_status()
            total = int(r.headers.get("Content-Length", 0))
            with open(tmp_file, "wb") as f, tqdm(total=total, unit="B", unit_scale=True) as bar:
                for chunk in r.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        bar.update(len(chunk))

        with zipfile.ZipFile(tmp_file, "r") as zf:
            zf.extractall(self.models_dir)
        os.remove(tmp_file)
        print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")

    # === –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ Vosk ===
    def _load_vosk_recognizers(self):
        recs = {}
        for lang, path in self.vosk_models.items():
            if path.exists():
                model = Model(str(path))
                recs[lang] = KaldiRecognizer(model, 16000)
        return recs

    # === –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫ ===
    def _start_microphone_stream(self):
        def callback(indata, frames, time_, status):
            if status:
                print(f"[AUDIO WARNING] {status}")
            self.audio_queue.put(bytes(indata))

        print("üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω –∞–∫—Ç–∏–≤–µ–Ω (–ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π —Ä–µ–∂–∏–º)")
        self.stream = sd.RawInputStream(
            samplerate=16000,
            blocksize=8000,
            dtype="int16",
            channels=1,
            callback=callback
        )
        self.stream.start()

    # === –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ ===
    def listen_text(self):
        """
        –°–ª—É—à–∞–µ—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç, –∫–æ–≥–¥–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ —Ñ—Ä–∞–∑–∞.
        """
        if self.mode == "online":
            return self._listen_online()
        else:
            return self._listen_offline()

    # === –û–Ω–ª–∞–π–Ω (Google) ===
    def _listen_online(self):
        print("üéôÔ∏è (Online) –ì–æ–≤–æ—Ä–∏—Ç–µ...")

        samplerate = 16000
        duration = 5

        try:
            with sd.InputStream(samplerate=samplerate, channels=1, dtype="int16") as stream:
                audio_data = stream.read(int(samplerate * duration))[0]
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞—É–¥–∏–æ-–ø–æ—Ç–æ–∫–∞: {e}")
            return "", self.default_lang

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ wav –∏ Google Speech
        wav_bytes = io.BytesIO()
        wav_write(wav_bytes, samplerate, audio_data)
        wav_bytes.seek(0)

        r = sr.Recognizer()
        with sr.AudioFile(wav_bytes) as source:
            audio = r.record(source)

        lang_code = self.language_map.get(self.default_lang, "ru-RU")
        try:
            text = r.recognize_google(audio, language=lang_code)
            print(f"üß† –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ ({self.default_lang.upper()}): {text}")
            return text, self.default_lang
        except sr.UnknownValueError:
            print("ü§î –ù–µ –ø–æ–Ω—è–ª, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ...")
            return "", self.default_lang
        except sr.RequestError:
            print("‚ö†Ô∏è –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –ø—Ä–æ–ø–∞–ª ‚Äî –æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º.")
            self.mode = "offline"
            return self._listen_offline()

    # === –û—Ñ–ª–∞–π–Ω (Vosk) ===
    def _listen_offline(self):
        lang = self.default_lang
        recognizer = self.vosk_recognizers.get(lang)
        if not recognizer:
            print(f"‚ö†Ô∏è –ù–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è {lang.upper()}")
            return "", lang

        while True:
            data = self.audio_queue.get()
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                text = result.get("text", "").strip()
                if text:
                    print(f"üó£Ô∏è {text}")
                    return text, lang

    # === –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ===
    def _collect_audio(self, seconds=5):
        """–°–æ–±–∏—Ä–∞–µ—Ç –∞—É–¥–∏–æ –±–ª–æ–∫–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è."""
        frames = []
        start = sd.get_stream().time if self.stream else 0
        duration = seconds
        while True:
            try:
                frames.append(self.audio_queue.get(timeout=seconds))
                if len(frames) * 0.5 > duration:  # –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ seconds
                    break
            except queue.Empty:
                break
        if not frames:
            return None
        import numpy as np
        return np.frombuffer(b"".join(frames), dtype="int16")

# import os
# import sys
# import json
# import queue
# import requests
# import zipfile
# import sounddevice as sd
# import io
# import tempfile
# from pathlib import Path
# from tqdm import tqdm
# from vosk import Model, KaldiRecognizer, SetLogLevel
# import speech_recognition as sr
# from scipy.io.wavfile import write as wav_write


# class Recognizer:
#     """
#     –ì–æ–ª–æ—Å–æ–≤–æ–π Recognizer –±–µ–∑ PyAudio:
#     - –û–Ω–ª–∞–π–Ω —á–µ—Ä–µ–∑ Google Speech
#     - –û—Ñ—Ñ–ª–∞–π–Ω —á–µ—Ä–µ–∑ Vosk
#     - –†–∞–±–æ—Ç–∞–µ—Ç —Å sounddevice
#     """

#     def __init__(self, config):
#         self.config = config
#         self.default_lang = (
#             config.get("assistant", {}).get("default_language", "ru")
#         )
#         self.language_map = {
#             "ru": "ru-RU",
#             "en": "en-US",
#             "uz": "uz-UZ"
#         }

#         self.models_dir = Path("data/models")
#         self.models_dir.mkdir(parents=True, exist_ok=True)

#         # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
#         self.vosk_models = {
#             "ru": self.models_dir / "vosk-model-small-ru-0.22",
#             "en": self.models_dir / "vosk-model-small-en-us-0.15",
#             "uz": self.models_dir / "vosk-model-small-uz-0.22",
#         }

#         # –°—Å—ã–ª–∫–∏ –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
#         self.vosk_urls = {
#             "ru": "https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip",
#             "en": "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip",
#             "uz": "https://alphacephei.com/vosk/models/vosk-model-small-uz-0.22.zip",
#         }

#         SetLogLevel(-1)
#         self.online_available = self._check_internet()
#         self._ensure_vosk_models()
#         self.vosk_recognizers = self._load_vosk_recognizers()

#         if self.online_available:
#             self.mode = "online"
#             print("üåê –†–µ–∂–∏–º: ONLINE (Google Speech Recognition)")
#         else:
#             self.mode = "offline"
#             print("‚öôÔ∏è –†–µ–∂–∏–º: OFFLINE (Vosk Speech Recognition)")

#         print(f"üó£Ô∏è –¢–µ–∫—É—â–∏–π —è–∑—ã–∫: {self.default_lang.upper()}")
        
#     # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ ===
#     def _check_internet(self):
#         try:
#             requests.get("https://www.google.com", timeout=3)
#             return True
#         except requests.RequestException:
#             return False

#     # === –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª–∏ Vosk ===
#     def _ensure_vosk_models(self):
#         for lang, path in self.vosk_models.items():
#             if not path.exists():
#                 if self.online_available:
#                     print(f"üì¶ –°–∫–∞—á–∏–≤–∞—é –º–æ–¥–µ–ª—å –¥–ª—è {lang.upper()}...")
#                     self._download_model(self.vosk_urls[lang])
#                 else:
#                     print(f"‚ùå –ù–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è {lang.upper()} –∏ –Ω–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.")
#                     sys.exit(1)

#     def _download_model(self, url):
#         tmp_dir = tempfile.gettempdir()
#         tmp_file = os.path.join(tmp_dir, "vosk_model.zip")
#         print(f"‚¨áÔ∏è –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å –∏–∑ {url}")

#         with requests.get(url, stream=True, timeout=30) as r:
#             r.raise_for_status()
#             total = int(r.headers.get("Content-Length", 0))
#             with open(tmp_file, "wb") as f, tqdm(
#                 total=total, unit="B", unit_scale=True, desc="üì¶ –ó–∞–≥—Ä—É–∑–∫–∞"
#             ) as bar:
#                 for chunk in r.iter_content(chunk_size=8192):
#                     if chunk:
#                         f.write(chunk)
#                         bar.update(len(chunk))

#         if not zipfile.is_zipfile(tmp_file):
#             print("‚ùå –û—à–∏–±–∫–∞: –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ ZIP.")
#             sys.exit(1)

#         with zipfile.ZipFile(tmp_file, "r") as zf:
#             zf.extractall(self.models_dir)

#         os.remove(tmp_file)
#         print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")

#     # === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π ===
#     def _load_vosk_recognizers(self):
#         recs = {}
#         for lang, path in self.vosk_models.items():
#             if path.exists():
#                 try:
#                     model = Model(str(path))
#                     recs[lang] = KaldiRecognizer(model, 16000)
#                     print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∏–ª –æ—Ñ–ª–∞–π–Ω –º–æ–¥–µ–ª—å: {lang.upper()}")
#                 except Exception as e:
#                     print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {lang}: {e}")
#         return recs

#     # === –û—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ ===
#     def listen_text(self, multilang=True, phrase_time_limit=None):
#         """
#         –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂: (—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, —è–∑—ã–∫)
#         """

#         if self.mode == "online":
#             return self._listen_online(multilang)
#         else:
#             return self._listen_offline()

#     # === –û–Ω–ª–∞–π–Ω —á–µ—Ä–µ–∑ sounddevice + Google Speech ===
#     def _listen_online(self, multilang=True):
#         print("üéôÔ∏è (Online) –ì–æ–≤–æ—Ä–∏—Ç–µ...")

#         samplerate = 16000
#         duration = 5  # —Å–µ–∫—É–Ω–¥ –∑–∞–ø–∏—Å–∏

#         audio_data = sd.rec(
#             int(samplerate * duration),
#             samplerate=samplerate,
#             channels=1,
#             dtype="int16"
#         )
#         sd.wait()

#         # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ AudioData (–¥–ª—è speech_recognition)
#         wav_bytes = io.BytesIO()
#         wav_write(wav_bytes, samplerate, audio_data)
#         wav_bytes.seek(0)

#         r = sr.Recognizer()
#         with sr.AudioFile(wav_bytes) as source:
#             audio = r.record(source)

#         lang_code = self.language_map.get(self.default_lang, "ru-RU")

#         try:
#             text = r.recognize_google(audio, language=lang_code)
#             print(f"üß† –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ ({self.default_lang.upper()}): {text}")            
#             return text, self.default_lang
        
#         except sr.UnknownValueError:
#             print("ü§î –ù–µ –ø–æ–Ω—è–ª, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ...")
#             return "", self.default_lang
        
#         except sr.RequestError:
#             print("‚ö†Ô∏è –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –ø—Ä–æ–ø–∞–ª ‚Äî –æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º.")
#             self.mode = "offline"
#             return self._listen_offline()

#     # === –û—Ñ–ª–∞–π–Ω —á–µ—Ä–µ–∑ Vosk ===
#     def _listen_offline(self):
#         lang = self.default_lang
#         recognizer = self.vosk_recognizers.get(lang)
#         if not recognizer:
#             print(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –¥–ª—è {lang.upper()} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
#             return "", lang

#         print(f"üéôÔ∏è (Offline {lang.upper()}) –ì–æ–≤–æ—Ä–∏—Ç–µ...")

#         q = queue.Queue()

#         def callback(indata, frames, time_, status):
#             q.put(bytes(indata))

#         with sd.RawInputStream(samplerate=16000, blocksize=8000,
#                                dtype="int16", channels=1, callback=callback):
#             while True:
#                 data = q.get()
#                 if recognizer.AcceptWaveform(data):
#                     result = json.loads(recognizer.Result())
#                     text = result.get("text", "").strip()
#                     if text:
#                         print(f"üó£Ô∏è {text}")
#                         print(f"üß† –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ ({lang.upper()}): {text}")
#                         return text, lang
