import os
import json
import queue
import requests
import zipfile
import sounddevice as sd
import io
import tempfile
from pathlib import Path
from tqdm import tqdm
from vosk import Model, KaldiRecognizer, SetLogLevel
import speech_recognition as sr
from scipy.io.wavfile import write as wav_write
from src.utils import logger


class Recognizer:
    """
    –ü–æ—Å—Ç–æ—è–Ω–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã–π Recognizer:
    - –û–Ω–ª–∞–π–Ω (Google Speech)
    - –û—Ñ—Ñ–ª–∞–π–Ω (Vosk)
    - –ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –≤—ã–∫–ª—é—á–∞–µ—Ç—Å—è –º–µ–∂–¥—É —Ñ—Ä–∞–∑–∞–º–∏
    """

    def __init__(self, config):
        self.logger = logger
        self.config = config
        self.default_lang = config.get("assistant", {}).get("default_language", "ru")
        self.language_map = {"ru": "ru-RU", "en": "en-US", "uz": "uz-UZ"}

        self.models_dir = Path("data/models")
        self.models_dir.mkdir(parents=True, exist_ok=True)

        self.vosk_models = {
            "ru": self.models_dir / "vosk-model-small-ru-0.22",
            "en": self.models_dir / "vosk-model-small-en-us-0.15",
            "uz": self.models_dir / "vosk-model-small-uz-0.22",
        }

        self.vosk_urls = {
            "ru": "https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip",
            "en": "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip",
            "uz": "https://alphacephei.com/vosk/models/vosk-model-small-uz-0.22.zip",
        }

        SetLogLevel(-1)
        self.online_available = self._check_internet()
        self._ensure_vosk_models()
        self.vosk_recognizers = self._load_vosk_recognizers()

        self.mode = "online" if self.online_available else "offline"
        self.logger.info(f"üåê –†–µ–∂–∏–º: {self.mode.upper()}")
        self.logger.info(f"üó£Ô∏è –¢–µ–∫—É—â–∏–π —è–∑—ã–∫: {self.default_lang.upper()}")

        # –û—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ –∏ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –ø–æ—Ç–æ–∫
        self.audio_queue = queue.Queue()
        self.stream = None
        self._start_microphone_stream()

    # === –ò–Ω—Ç–µ—Ä–Ω–µ—Ç ===
    def _check_internet(self):
        try:
            requests.get("https://www.google.com", timeout=3)
            return True
        except requests.RequestException:
            return False

    # === –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏ ===
    def _ensure_vosk_models(self):
        for lang, path in self.vosk_models.items():
            if not path.exists() and self.online_available:
                self.logger.info(f"üì¶ –°–∫–∞—á–∏–≤–∞—é –º–æ–¥–µ–ª—å –¥–ª—è {lang.upper()}...")
                self._download_model(self.vosk_urls[lang])

    def _download_model(self, url):
        tmp_file = Path(tempfile.gettempdir()) / "vosk_model.zip"
        with requests.get(url, stream=True, timeout=30) as r:
            r.raise_for_status()
            total = int(r.headers.get("Content-Length", 0))
            with open(tmp_file, "wb") as f, tqdm(total=total, unit="B", unit_scale=True) as bar:
                for chunk in r.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        bar.update(len(chunk))

        with zipfile.ZipFile(tmp_file, "r") as zf:
            zf.extractall(self.models_dir)
        os.remove(tmp_file)
        self.logger.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!")

    # === –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ Vosk ===
    def _load_vosk_recognizers(self):
        recs = {}
        for lang, path in self.vosk_models.items():
            if path.exists():
                model = Model(str(path))
                recs[lang] = KaldiRecognizer(model, 16000)
        return recs

    # === –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫ ===
    def _start_microphone_stream(self):
        def callback(indata, frames, time_, status):
            if status:
                self.logger.info(f"[AUDIO WARNING] {status}")
            self.audio_queue.put(bytes(indata))

        self.logger.info("üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω –∞–∫—Ç–∏–≤–µ–Ω (–ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π —Ä–µ–∂–∏–º)")
        self.stream = sd.RawInputStream(
            samplerate=16000,
            blocksize=8000,
            dtype="int16",
            channels=1,
            callback=callback
        )
        self.stream.start()

    # === –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ ===
    def listen_text(self):
        """
        –°–ª—É—à–∞–µ—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç, –∫–æ–≥–¥–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ —Ñ—Ä–∞–∑–∞.
        """
        if self.mode == "online":
            return self._listen_online()
        else:
            return self._listen_offline()

    # === –û–Ω–ª–∞–π–Ω (Google) ===
    def _listen_online(self):
        self.logger.info("üéôÔ∏è (Online) –ì–æ–≤–æ—Ä–∏—Ç–µ...")

        samplerate = 16000
        duration = 5

        try:
            with sd.InputStream(samplerate=samplerate, channels=1, dtype="int16") as stream:
                audio_data = stream.read(int(samplerate * duration))[0]
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞—É–¥–∏–æ-–ø–æ—Ç–æ–∫–∞: {e}")
            return "", self.default_lang

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ wav –∏ Google Speech
        wav_bytes = io.BytesIO()
        wav_write(wav_bytes, samplerate, audio_data)
        wav_bytes.seek(0)

        r = sr.Recognizer()
        with sr.AudioFile(wav_bytes) as source:
            audio = r.record(source)

        lang_code = self.language_map.get(self.default_lang, "ru")
        try:
            text = r.recognize_google(audio, language=lang_code)
            self.logger.info(f"üß† –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ ({self.default_lang.upper()}): {text}")
            return text, self.default_lang
        except sr.UnknownValueError:
            self.logger.warning("ü§î –ù–µ –ø–æ–Ω—è–ª, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ...")
            return "", self.default_lang
        except sr.RequestError:
            self.logger.warning("‚ö†Ô∏è –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –ø—Ä–æ–ø–∞–ª ‚Äî –æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º.")
            self.mode = "offline"
            return self._listen_offline()

    # === –û—Ñ–ª–∞–π–Ω (Vosk) ===
    def _listen_offline(self):
        lang = self.default_lang
        recognizer = self.vosk_recognizers.get(lang)
        if not recognizer:
            self.logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è {lang.upper()}")
            return "", lang

        while True:
            data = self.audio_queue.get()
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                text = result.get("text", "").strip()
                if text:
                    self.logger.info(f"üó£Ô∏è {text}")
                    return text, lang

    # === –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ===
    def _collect_audio(self, seconds=5):
        """–°–æ–±–∏—Ä–∞–µ—Ç –∞—É–¥–∏–æ –±–ª–æ–∫–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è."""
        frames = []
        start = sd.get_stream().time if self.stream else 0
        duration = seconds
        while True:
            try:
                frames.append(self.audio_queue.get(timeout=seconds))
                if len(frames) * 0.5 > duration:  # –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ seconds
                    break
            except queue.Empty:
                break
        if not frames:
            return None
        import numpy as np
        return np.frombuffer(b"".join(frames), dtype="int16")

    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –æ—á–∏—â–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å."""
        try:
            if self.stream:
                self.stream.stop()
                self.stream.close()
                self.stream = None
            with self.audio_queue.mutex:
                self.audio_queue.queue.clear()
            self.logger.warning("üõë –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}")
