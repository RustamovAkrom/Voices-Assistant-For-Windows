"""
Optimized main.py for Jarvis-like assistant.

Features:
- Threaded TTS and recognizer workers
- speaking Event to avoid recognizing own speech
- wake-word detection with regex-word boundaries
- active-mode with timeout that refreshes on commands
- safe skill/context passing
- graceful shutdown and reload commands
"""

import time
import re
import threading
import queue
import logging
from typing import Optional

from src.core.recognizer import Recognizer
from src.core.tts import HybridTTS
from src.core.skill_manager import SkillManager
from src.core.executor import Executor
from src.core.config import get_settings

# -----------------------
# Logger
# -----------------------
logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger("Jarvis")

# -----------------------
# Globals / Queues / Events
# -----------------------
tts_queue: "queue.Queue[tuple[str, Optional[str]]]" = queue.Queue()
recognizer_queue: "queue.Queue[tuple[str, Optional[str]]]" = queue.Queue()
SHUTDOWN = threading.Event()
SPEAKING = threading.Event()          # set while TTS playing to avoid self-recognition
WORKERS: list[threading.Thread] = []

# Tunables (–º–æ–∂–µ—Ç–µ –º–µ–Ω—è—Ç—å –≤ config.yaml)
DEFAULT_ACTIVE_TIMEOUT = 20.0         # seconds assistant stays active after wake
RECOGNIZER_BACKOFF = 0.12             # sleep between recognizer loop iterations
MISUNDERSTAND_LIMIT = 3               # —Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ä—è–¥ –ø—É—Å—Ç—ã—Ö —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–π -> prompt

# -----------------------
# TTS worker
# -----------------------
def tts_worker(tts: HybridTTS):
    """
    –î–æ—á–µ—Ä–Ω–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è.
    –ü–æ–º–µ—á–∞–µ—Ç SPEAKING –≤–æ –≤—Ä–µ–º—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è, —á—Ç–æ–±—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª —Å–≤–æ–∏ –∂–µ –∑–≤—É–∫–∏.
    """
    logger.debug("TTS worker started")
    while not SHUTDOWN.is_set():
        try:
            item = tts_queue.get(timeout=0.5)
        except queue.Empty:
            continue

        try:
            text, lang = item
            if not text:
                continue
            # set speaking flag so recognizer can skip audio while we output
            SPEAKING.set()
            logger.info(f"[TTS] Speaking ({lang}): {text}")
            try:
                # HybridTTS.speak is blocking (plays and waits)
                tts.speak(text, lang)
            except Exception as e:
                logger.exception(f"[TTS ERROR] {e}")
            finally:
                # small safety sleep to let audio device drain
                time.sleep(0.12)
                SPEAKING.clear()
        finally:
            tts_queue.task_done()
    logger.info("TTS worker stopped")


# -----------------------
# Recognizer worker
# -----------------------
def recognizer_worker(recognizer: Recognizer, silence_threshold: float = 3.0):
    """
    –ü—Ä–æ—Å—Ç–∞—è, –Ω–æ –Ω–∞–¥–µ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.
    - —Å–ª—É—à–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –∫—É—Å–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Recognizer.listen_text()
    - –µ—Å–ª–∏ SPEAKING —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–º—ã –≥–æ–≤–æ—Ä–∏–º —Å–∞–º–∏)
    - –ø–æ–º–µ—â–∞–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –≤ recognizer_queue
    """
    logger.debug("Recognizer worker started")
    misunderstand_count = 0

    while not SHUTDOWN.is_set():
        try:
            # listen_text() –¥–æ–ª–∂–µ–Ω –±—ã—Å—Ç—Ä–æ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏–±–æ ("", lang) –ª–∏–±–æ (text, lang)
            result = recognizer.listen_text()
        except Exception as e:
            logger.exception(f"[Recognizer ERROR] {e}")
            time.sleep(0.5)
            continue

        if SPEAKING.is_set():
            # –µ—Å–ª–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å–µ–π—á–∞—Å –≥–æ–≤–æ—Ä–∏—Ç ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç "—Å–ª—ã—à–∏—Ç —Å–∞–º —Å–µ–±—è")
            logger.debug("Recognizer skipped because assistant is speaking")
            time.sleep(RECOGNIZER_BACKOFF)
            continue

        if not result:
            # –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –∏, –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –ø–æ—Ä–æ–≥–∞, —É–≤–µ–¥–æ–º–ª—è–µ–º
            misunderstand_count += 1
            if misunderstand_count >= MISUNDERSTAND_LIMIT:
                # –¥–µ–ª–∞–µ–º –º—è–≥–∫–∏–π –ø–æ–¥—Å–∫–∞–∑
                try:
                    recognizer_queue.put(("", None))
                except Exception:
                    pass
                misunderstand_count = 0
            time.sleep(RECOGNIZER_BACKOFF)
            continue

        # —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –Ω–µ–ø–æ–Ω—è—Ç—ã—Ö –ø—Ä–∏ —Ä–µ–∞–ª—å–Ω–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
        misunderstand_count = 0

        text, lang = result
        if not text:
            # –∏–Ω–æ–≥–¥–∞ listen_text –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç ("", lang)
            time.sleep(RECOGNIZER_BACKOFF)
            continue

        # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        text = text.strip()
        if not text:
            continue

        try:
            recognizer_queue.put((text, lang))
            logger.debug(f"Recognizer -> queue: ({lang}) {text}")
        except Exception as e:
            logger.exception(f"Failed to queue recognition result: {e}")
            time.sleep(RECOGNIZER_BACKOFF)

    logger.info("Recognizer worker stopped")


# -----------------------
# Helpers
# -----------------------
def build_wake_words(config: dict) -> set:
    wake_words = set()
    wake_cfg = config.get("wake_words", {}) or {}
    if isinstance(wake_cfg, dict):
        for lang_words in wake_cfg.values():
            if isinstance(lang_words, (list, tuple)):
                for w in lang_words:
                    wake_words.add(w.lower().strip())
    # backward compat
    single = config.get("wake_word")
    if single:
        wake_words.add(str(single).lower().strip())
    return wake_words


def remove_wake_word(text: str, wake_word: Optional[str]) -> str:
    if not text:
        return ""
    if not wake_word:
        return text.strip().lower()
    # use word boundaries to avoid accidental partial matches
    cleaned = re.sub(rf"\b{re.escape(wake_word)}\b", "", text, flags=re.IGNORECASE)
    return cleaned.strip().lower()


def is_reload_command(text: str, meta: dict, key: str) -> bool:
    if not (text and meta):
        return False
    patterns = meta.get(key, {}).get("patterns", []) or []
    return any(text == p.lower() for p in patterns)


# -----------------------
# Text processing core
# -----------------------
def process_text(executor: Executor, dataset: dict, skills: SkillManager,
                 text: str, lang: Optional[str], wake_words: set, active_state: dict):
    """
    –ì–ª–∞–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞: wake-word -> activation -> commands -> execution
    active_state = { "active": bool, "last": float, "timeout": float }
    """
    if not text:
        # empty text used as a 'prompt' for user to repeat
        logger.debug("Empty prompt received (user silent)")
        return

    normalized = text.lower().strip()
    lang = (lang or active_state.get("lang") or "ru").lower()
    logger.info(f"üß† –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ ({lang}): {normalized}")

    # If not active ‚Äî check wake words
    if not active_state["active"]:
        # find whole-word wake
        triggered = next((w for w in wake_words if re.search(rf"\b{re.escape(w)}\b", normalized)), None)
        if triggered:
            cleaned = remove_wake_word(normalized, triggered)
            # go active and update timer
            active_state["active"] = True
            active_state["last"] = time.time()
            active_state["lang"] = lang
            logger.info(f"üöÄ Wake word activated: '{triggered}' (lang={lang})")
            # If there's immediate content after wake, execute it
            if cleaned:
                logger.info(f"üöÄ Immediate command after wake: {cleaned}")
                _execute_and_respond(executor, skills, dataset, cleaned, lang)
            else:
                # acknowledgement
                tts_queue.put(("–°–ª—É—à–∞—é –≤–∞—Å.", lang))
        else:
            logger.debug("No wake word detected and assistant inactive -> ignoring")
        return

    # if active: check timeout
    if time.time() - active_state["last"] > active_state["timeout"]:
        logger.info("üò¥ Active timeout expired. Deactivating.")
        active_state["active"] = False
        return

    # refresh last active time on any recognized text
    active_state["last"] = time.time()

    # remove wake word if present in ongoing conversation
    triggered = next((w for w in wake_words if re.search(rf"\b{re.escape(w)}\b", normalized)), None)
    cleaned_text = remove_wake_word(normalized, triggered) if triggered else normalized

    if not cleaned_text:
        # nothing after wake word
        tts_queue.put(("–î–∞, —è —Å–ª—É—à–∞—é.", lang))
        return

    meta = dataset.get("meta", {}) or {}

    # special meta commands (reload dataset, restart skills)
    if is_reload_command(cleaned_text, meta, "reload_dataset"):
        logger.info("üîÅ Reload dataset command received")
        settings = get_settings()
        dataset = settings.dataset
        executor.update_dataset(dataset)
        skills.reload()
        resp = meta.get("reload_dataset", {}).get("response", {}).get(lang, "–î–∞—Ç–∞—Å–µ—Ç –æ–±–Ω–æ–≤–ª—ë–Ω.")
        tts_queue.put((resp, lang))
        return

    if is_reload_command(cleaned_text, meta, "restart_skills"):
        logger.info("üîÅ Restart skills command received")
        skills.reload()
        resp = meta.get("restart_skills", {}).get("response", {}).get(lang, "–ù–∞–≤—ã–∫–∏ –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω—ã.")
        tts_queue.put((resp, lang))
        return

    # run the command(s) via Executor
    _execute_and_respond(executor, skills, dataset, cleaned_text, lang)


def _execute_and_respond(executor: Executor, skills: SkillManager, dataset: dict, text: str, lang: str):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç Executor.handle (–∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç matcher –∏ SkillManager),
    –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–≤–µ—Ç –≤ tts_queue. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —É–∂–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç –∫–∞–∫ dict (multi-lang),
    –ø—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –æ—Ç–≤–µ—Ç –ø–æ lang.
    """
    try:
        response = executor.handle(text, lang=lang)
    except Exception as e:
        logger.exception(f"Executor error: {e}")
        response = {
            "ru": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã.",
            "en": "An error occurred executing the command.",
            "uz": "Buyruqni bajarishda xato yuz berdi."
        }.get(lang, "–û—à–∏–±–∫–∞.")

    # response can be a dict (meta) or string
    if isinstance(response, dict):
        out = response.get(lang) or response.get("en") or next(iter(response.values()), "")
    else:
        out = str(response) if response is not None else ""

    if out:
        tts_queue.put((out, lang))
    else:
        tts_queue.put(("–ù–µ –ø–æ–Ω—è–ª, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ.", lang))


# -----------------------
# Orchestrator / main
# -----------------------
def main():
    settings = get_settings()
    config = settings.config or {}
    dataset = settings.dataset or {}

    # init components
    recognizer = Recognizer(config)
    tts = HybridTTS(config)

    # context that will be passed into SkillManager (so skills can access config/dataset/tts/etc.)
    context = {"config": config, "dataset": dataset, "workers": WORKERS, "tts": tts}
    skills = SkillManager(context=context)
    executor = Executor(dataset, skills, config=config)

    wake_words = build_wake_words(config)
    logger.info(f"üéß Wake words: {', '.join(sorted(wake_words)) or 'NONE'}")

    # start workers
    t_worker = threading.Thread(target=tts_worker, args=(tts,), daemon=True, name="TTS-Worker")
    r_worker = threading.Thread(target=recognizer_worker, args=(recognizer,), daemon=True, name="Recognizer-Worker")
    t_worker.start()
    r_worker.start()
    WORKERS.extend([t_worker, r_worker])

    # active state
    active_state = {"active": False, "last": 0.0, "timeout": config.get("assistant", {}).get("active_timeout", DEFAULT_ACTIVE_TIMEOUT), "lang": config.get("assistant", {}).get("default_language", "ru")}

    logger.info("ü§ñ Jarvis started and listening...")

    try:
        while not SHUTDOWN.is_set():
            try:
                text, lang = recognizer_queue.get(timeout=0.2)
            except queue.Empty:
                continue

            # process_text does internal checks for active state, wake words etc.
            try:
                process_text(executor, dataset, skills, text, lang, wake_words, active_state)
            except Exception as e:
                logger.exception(f"[PROCESS ERROR] {e}")
            finally:
                recognizer_queue.task_done()

    except KeyboardInterrupt:
        logger.info("üõë KeyboardInterrupt ‚Äî shutting down...")

    finally:
        # Graceful shutdown
        SHUTDOWN.set()
        logger.info("Waiting for queues to drain...")
        try:
            tts_queue.join()
        except Exception:
            pass
        logger.info("Stopping workers...")
        # If Recognizer has stop method, call it
        try:
            recognizer.stop()
        except Exception:
            pass

        for w in WORKERS:
            if w.is_alive():
                logger.debug(f"Joining worker {w.name}")
                w.join(timeout=1.0)

        logger.info("Jarvis stopped.")


if __name__ == "__main__":
    main()

# import time
# import re
# import threading
# import queue
# import logging

# from src.core.recognizer import Recognizer
# from src.core.tts import HybridTTS
# from src.core.skill_manager import SkillManager
# from src.core.executor import Executor
# from src.core.config import get_settings

# # === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
# logging.basicConfig(
#     level=logging.INFO,
#     format="[%(asctime)s] [%(levelname)s] %(message)s",
#     datefmt="%H:%M:%S",
# )
# logger = logging.getLogger("Jarvis")

# # === –û—á–µ—Ä–µ–¥–∏ –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è ===
# WORKERS = []
# tts_queue = queue.Queue()
# recognizer_queue = queue.Queue()


# # === –ü–æ—Ç–æ–∫ TTS ===
# def tts_worker(tts: HybridTTS):
#     """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å –æ–∑–≤—É—á–∫–∏"""
#     while True:
#         text, lang = tts_queue.get()
#         try:
#             if text:
#                 tts.speak(text, lang)
#         except Exception as e:
#             logger.error(f"[TTS ERROR] {e}")
#         finally:
#             tts_queue.task_done()

# def recognizer_worker(recognizer: Recognizer, silence_threshold=3.0):
#     """
#     –ë–∞–∑–æ–≤–∞—è —Ä–∞–±–æ—á–∞—è –ª–æ–≥–∏–∫–∞ ‚Äî —Å—Ä–∞–∑—É –ø–æ–º–µ—â–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –≤ –æ—á–µ—Ä–µ–¥—å.
#     (–ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –ø–∞—É–∑–µ –º–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –ø–æ–∑–¥–Ω–µ–µ)
#     """
#     miss_count = 0
#     miss_threshold = 3

#     while True:
#         try:
#             result = recognizer.listen_text()
#             if result:
#                 miss_count = 0
#                 text, lang = result
#                 if text:
#                     recognizer_queue.put((text.strip(), lang))
#             else:
#                 miss_count += 1
#                 if miss_count >= miss_threshold:
#                     tts_queue.put(("–ò–∑–≤–∏–Ω–∏, —è –Ω–µ –ø–æ–Ω—è–ª, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ...", recognizer.default_lang))
#                     logger.info("ü§î –ù–µ –ø–æ–Ω—è–ª, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ...")
#                     miss_count = 0
#                 time.sleep(0.05)
#         except Exception as e:
#             logger.error(f"[Recognizer ERROR] {e}")
#             time.sleep(0.5)

# # === –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ===
# def clean_text(text: str, wake_word: str = None) -> str:
#     """–£–¥–∞–ª—è–µ—Ç wake word –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
#     if not text:
#         return ""
#     if wake_word:
#         text = re.sub(rf"\b{re.escape(wake_word)}\b", "", text, flags=re.IGNORECASE)
#     return text.strip().lower()


# def is_reload_command(text: str, meta: dict, key: str) -> bool:
#     """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∫–æ–º–∞–Ω–¥–∞ –∫–æ–º–∞–Ω–¥–æ–π –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏"""
#     if not text or not meta:
#         return False
#     patterns = meta.get(key, {}).get("patterns", [])
#     return any(text == p.lower() for p in patterns)


# def build_wake_words(config: dict) -> set:
#     """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ —Å–ª–æ–≤–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
#     wake_words = set()

#     for lang, words in (config.get("wake_words") or {}).items():
#         if isinstance(words, list):
#             wake_words.update(map(str.lower, words))

#     # –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä–æ–µ –ø–æ–ª–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
#     single_word = config.get("wake_word")
#     if single_word:
#         wake_words.add(single_word.lower())

#     return wake_words


# # === –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ ===
# def process_text(executor: Executor, dataset: dict, skills: SkillManager,
#                  text: str, lang: str, wake_words: set,
#                  active_state: dict):
#     """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""

#     normalized = text.lower().strip()
#     lang = lang or "ru"
#     logger.info(f"üß† –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ ({lang}): {normalized}")

#     # === –û–±—Ä–∞–±–æ—Ç–∫–∞ Wake Word ===
#     if not active_state["active"]:
#         triggered = next((w for w in wake_words if re.search(rf"\b{re.escape(w)}\b", normalized)), None)

#         if triggered:
#             cleaned = clean_text(normalized, triggered)
#             active_state["active"] = True
#             active_state["last"] = time.time()

#             if not cleaned:
#                 logger.info(f"üöÄ –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω wake word: '{triggered}'")
#                 tts_queue.put(("–°–ª—É—à–∞—é –≤–∞—Å.", lang))
#                 return

#             logger.info(f"üöÄ Wake word '{triggered}', —Å—Ä–∞–∑—É –≤—ã–ø–æ–ª–Ω—è—é –∫–æ–º–∞–Ω–¥—É: {cleaned}")
#             response = executor.handle(cleaned, lang=lang)
#             if response:
#                 tts_queue.put((response, lang))
#             return
#         return  # –Ω–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω ‚Äî –∂–¥—ë–º wake word

#     # === –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–π–º-–∞—É—Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ ===
#     if time.time() - active_state["last"] > active_state["timeout"]:
#         logger.info("üò¥ –í—Ä–µ–º—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏—Å—Ç–µ–∫–ª–æ.")
#         active_state["active"] = False
#         return

#     # === –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥ ===
#     triggered = next((w for w in wake_words if w in normalized), None)
#     cleaned_text = clean_text(normalized, triggered)
#     if not cleaned_text:
#         tts_queue.put(("–î–∞, —è —Å–ª—É—à–∞—é.", lang))
#         return

#     meta = dataset.get("meta", {}) or {}

#     # === –°–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã ===
#     if is_reload_command(cleaned_text, meta, "reload_dataset"):
#         logger.info("üîÅ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
#         new_settings = get_settings()
#         dataset = new_settings.dataset
#         executor.update_dataset(dataset)
#         skills.reload()
#         msg = meta.get("reload_dataset", {}).get("response", {}).get(lang, "–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã.")
#         tts_queue.put((msg, lang))
#         return

#     if is_reload_command(cleaned_text, meta, "restart_skills"):
#         logger.info("üîÅ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –Ω–∞–≤—ã–∫–æ–≤...")
#         skills.reload()
#         msg = meta.get("restart_skills", {}).get("response", {}).get(lang, "–ù–∞–≤—ã–∫–∏ –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω—ã.")
#         tts_queue.put((msg, lang))
#         return

#     # === –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ===
#     response = executor.handle(cleaned_text, lang=lang)
#     if response:
#         tts_queue.put((response, lang))
#         active_state["last"] = time.time()
#     else:
#         tts_queue.put(("–ù–µ –ø–æ–Ω—è–ª, –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ.", lang))


# # === –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ ===
# def main():
#     settings = get_settings()
#     config = settings.config
#     dataset = settings.dataset

#     recognizer = Recognizer(config)
#     tts = HybridTTS(config)

#     context = {"config": config, "dataset": dataset, "workers": WORKERS, "tts": tts}
#     skills = SkillManager(context=context)
#     executor = Executor(dataset, skills, config=config)

#     wake_words = build_wake_words(config)
#     logger.info(f"üéß –°–ª–æ–≤–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: {', '.join(wake_words)}")

#     # === –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–æ–≤ ===
#     threading.Thread(target=tts_worker, args=(tts,), daemon=True).start()
#     threading.Thread(target=recognizer_worker, args=(recognizer,), daemon=True).start()

#     active_state = {"active": False, "last": 0.0, "timeout": 20.0}
#     logger.info("ü§ñ Jarvis –∑–∞–ø—É—â–µ–Ω –∏ —Å–ª—É—à–∞–µ—Ç...")

#     while True:
#         try:
#             text, lang = recognizer_queue.get(timeout=0.1)
#             if text:
#                 process_text(executor, dataset, skills, text, lang, wake_words, active_state)
#         except queue.Empty:
#             continue
#         except KeyboardInterrupt:
#             logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø–æ Ctrl+C")
#             break
#         except Exception as e:
#             logger.error(f"[MAIN ERROR] {e}")
#             time.sleep(0.3)


# if __name__ == "__main__":
#     main()
